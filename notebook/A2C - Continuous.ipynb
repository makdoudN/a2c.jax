{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d810083-09f7-486c-a107-4258c61ae762",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import jax\n",
    "import tax\n",
    "import tree\n",
    "import tqdm\n",
    "import optax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import haiku as hk\n",
    "\n",
    "from a2c.a2c import Data\n",
    "from a2c.a2c import State\n",
    "from a2c.a2c import Batch\n",
    "from a2c.a2c import update_a2c\n",
    "from jax import jit\n",
    "from jax import vmap\n",
    "from gym.vector import AsyncVectorEnv\n",
    "from functools import partial\n",
    "from common import gym_evaluation\n",
    "from common import gym_interaction\n",
    "\n",
    "tax.set_platform('cpu')\n",
    "rng = jax.random.PRNGKey(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635a3301-e130-49b9-9604-633842a34b0f",
   "metadata": {},
   "source": [
    "# `Initialization`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44ad4134-c7b7-40ca-aaf2-c92e62ffa825",
   "metadata": {},
   "outputs": [],
   "source": [
    "NENVS    = 8\n",
    "name     = 'Pendulum-v0'\n",
    "make_env = lambda: gym.make(name)\n",
    "\n",
    "env              = AsyncVectorEnv([make_env for _ in range(NENVS)])\n",
    "env_test         = gym.make(name)\n",
    "action_size      = env_test.action_space.shape[0]\n",
    "observation_size = env_test.observation_space.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bc415c7-06c7-4366-a149-d00ee235560d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(42)\n",
    "\n",
    "dummy_action      = jnp.zeros((action_size,))\n",
    "dummy_observation = jnp.zeros((observation_size,))\n",
    "\n",
    "policy_def = lambda x: tax.mlp_multivariate_normal_diag(\n",
    "    action_size, logstd_min=-10.0, logstd_max=3.0)(x)\n",
    "policy_def = hk.transform(policy_def)\n",
    "policy_def = hk.without_apply_rng(policy_def)\n",
    "policy_opt = getattr(optax, 'adabelief')(learning_rate=5e-4)\n",
    "value_def  = lambda x: tax.mlp_deterministic(1)(x).squeeze(-1)\n",
    "value_def  = hk.transform(value_def)\n",
    "value_def  = hk.without_apply_rng(value_def)\n",
    "value_opt  = getattr(optax, 'adabelief')(learning_rate=5e-4)\n",
    "\n",
    "rng, rng_policy, rng_value = jax.random.split(rng, 3)\n",
    "value_params               = value_def.init(rng_policy, dummy_observation)\n",
    "value_opt_state            = value_opt.init(value_params)\n",
    "policy_params              = policy_def.init(rng_policy, dummy_observation)\n",
    "policy_opt_state           = policy_opt.init(policy_params)\n",
    "\n",
    "params    = {'policy': policy_params, 'value': value_params}\n",
    "opt_state = {'policy': policy_opt_state, 'value': value_opt_state}\n",
    "state     = State(params=params, opt_state=opt_state, key=rng)\n",
    "\n",
    "policy_apply = jit(policy_def.apply)\n",
    "value_apply = jit(value_def.apply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c132c86e-545f-4051-a6cf-9974580d74ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction = gym_interaction(env, jit(policy_def.apply))\n",
    "interaction.send(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df1eb8ec-cdef-472a-8fcd-5f9410639393",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = interaction.send(state.params['policy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b9ba691-1f31-4061-af5f-7687c60f16d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gym_evaluation(rng, env_test, state.params['policy'], policy_apply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a327d141-0090-4486-bb0a-1e50ad69baa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_kwargs = {    \n",
    "    'policy_apply': policy_apply,\n",
    "    'value_apply': value_apply,\n",
    "}\n",
    "\n",
    "process_kwargs = {\n",
    "    'value_apply': value_apply,\n",
    "}\n",
    "\n",
    "loss_kwargs = hk.data_structures.to_immutable_dict(loss_kwargs)\n",
    "process_kwargs = hk.data_structures.to_immutable_dict(process_kwargs)\n",
    "update = partial(update_a2c,     \n",
    "    policy_opt=policy_opt.update, \n",
    "    value_opt=value_opt.update, \n",
    "    loss_kwargs=loss_kwargs, \n",
    "    process_data_kwargs=process_kwargs, \n",
    "    max_grad_norm=-1.0)\n",
    "update = jit(update)\n",
    "\n",
    "\n",
    "state, info = update(state, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd29a8c-bfd9-4008-a2d2-a17ab7612651",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = tax.Store()\n",
    "for _ in tqdm.notebook.trange(2000):\n",
    "    for _ in range(100):\n",
    "        data  = interaction.send(state.params['policy'])\n",
    "        state, update_info = update(state, data)\n",
    "        S.add(**update_info)\n",
    "    \n",
    "    eval_info = gym_evaluation(rng, env_test, state.params['policy'], policy_apply)\n",
    "    S.add(**eval_info)\n",
    "    info = S.get()\n",
    "    print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52d5059-90b2-46f5-a23c-65c099810a07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
